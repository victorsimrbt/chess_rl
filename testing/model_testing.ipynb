{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import chess"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "board = chess.Board()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from board_conversion import *\r\n",
    "\r\n",
    "def generate_side_matrix(board,side):\r\n",
    "    matrix = board_matrix(board)\r\n",
    "    translate = translate_board(board)\r\n",
    "    bools = np.array([piece.isupper() == side for piece in matrix])\r\n",
    "    bools = bools.reshape(8,8,1)\r\n",
    "    \r\n",
    "    side_matrix = translate*bools\r\n",
    "    return np.array(side_matrix)\r\n",
    "\r\n",
    "def generate_input(positions,len_positions = 8):\r\n",
    "    board_rep = []\r\n",
    "    for position in positions:\r\n",
    "        black = generate_side_matrix(board,False)\r\n",
    "        white = generate_side_matrix(board,True)\r\n",
    "        board_rep.append(black)\r\n",
    "        board_rep.append(white)\r\n",
    "    turn = np.zeros((8,8,12))\r\n",
    "    turn.fill(int(board.turn))\r\n",
    "    board_rep.append(turn)\r\n",
    "    \r\n",
    "    while len(board_rep) < len_positions*2 + 1:\r\n",
    "        value = np.zeros((8,8,12))\r\n",
    "        board_rep.insert(0,value)\r\n",
    "    board_rep = np.array(board_rep)\r\n",
    "    return board_rep\r\n",
    "    \r\n",
    "        \r\n",
    "input_matrix = generate_input([chess.Board()])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "input_matrix.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(17, 8, 8, 12)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from keras.models import Model\r\n",
    "from keras.layers import Input\r\n",
    "from keras.layers import Activation\r\n",
    "from keras.layers import Conv2D, Dense, add, BatchNormalization,Flatten\r\n",
    "\r\n",
    "def residual_module(layer_in, n_filters):\r\n",
    "\tmerge_input = layer_in\r\n",
    "\tif layer_in.shape[-1] != n_filters:\r\n",
    "\t\tmerge_input = Conv2D(n_filters, (1,1), padding='same', activation='relu', kernel_initializer='he_normal')(layer_in)\r\n",
    "\tconv1 = Conv2D(n_filters, (3,3), padding='same', activation='relu', kernel_initializer='he_normal')(layer_in)\r\n",
    "\tbatch_norm = BatchNormalization()(conv1)\r\n",
    "\tlayer_out = add([batch_norm, merge_input])\r\n",
    "\tlayer_out = Activation('relu')(layer_out)\r\n",
    "\treturn layer_out\r\n",
    "\r\n",
    "visible = Input(shape=(17, 8, 8,12))\r\n",
    "layer1 = residual_module(visible, 64)\r\n",
    "flatten = Flatten()(layer1)\r\n",
    "p = Dense(4096,activation='softmax',name = 'p')(flatten)\r\n",
    "v = Dense(1,activation = 'sigmoid',name = 'v')(flatten)\r\n",
    "# create model\r\n",
    "model = Model(inputs=visible, outputs=[p,v])\r\n",
    "# summarize model\r\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 17, 8, 8, 12 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 17, 8, 8, 64) 6976        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 17, 8, 8, 64) 256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 17, 8, 8, 64) 832         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 17, 8, 8, 64) 0           batch_normalization_15[0][0]     \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 17, 8, 8, 64) 0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 69632)        0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "p (Dense)                       (None, 4096)         285216768   flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "v (Dense)                       (None, 1)            69633       flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 285,294,465\n",
      "Trainable params: 285,294,337\n",
      "Non-trainable params: 128\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from keras.losses import CategoricalCrossentropy,BinaryCrossentropy\r\n",
    "import keras.optimizers\r\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.00025, clipnorm=1.0)\r\n",
    "model.compile(optimizer = optimizer, loss = {'p':CategoricalCrossentropy(),\r\n",
    "                                                     'v':BinaryCrossentropy()})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import numpy as np\r\n",
    "X = np.random.randn(12,17,8,8,12)\r\n",
    "y1 = np.random.randn(12,4096)\r\n",
    "y2 = np.random.randn(12,1)\r\n",
    "model.fit(X,[y1,y2])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/1 [==============================] - 6s 6s/step - loss: 379.6279 - p_loss: 377.2117 - v_loss: 2.4162\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2697b85aa90>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from keras.layers import Dense,Flatten\r\n",
    "from keras.layers.convolutional import Conv2D\r\n",
    "from keras.models import Model, Input\r\n",
    "import tensorflow as tf\r\n",
    "from board_conversion import *\r\n",
    "\r\n",
    "class Q_model():\r\n",
    "    def __init__(self,model = None):\r\n",
    "        if model:\r\n",
    "            print('CUSTOM MODEL SET')\r\n",
    "            self.model = model\r\n",
    "        else:\r\n",
    "            self.model = self.create_q_model()\r\n",
    "\r\n",
    "    def create_q_model(self):\r\n",
    "        def residual_module(layer_in, n_filters):\r\n",
    "            merge_input = layer_in\r\n",
    "            if layer_in.shape[-1] != n_filters:\r\n",
    "                merge_input = Conv2D(n_filters, (1,1), padding='same', activation='relu', kernel_initializer='he_normal')(layer_in)\r\n",
    "            conv1 = Conv2D(n_filters, (3,3), padding='same', activation='relu', kernel_initializer='he_normal')(layer_in)\r\n",
    "            batch_norm = BatchNormalization()(conv1)\r\n",
    "            layer_out = add([batch_norm, merge_input])\r\n",
    "            layer_out = Activation('relu')(layer_out)\r\n",
    "            return layer_out\r\n",
    "\r\n",
    "        visible = Input(shape=(17, 8, 8,12))\r\n",
    "        layer1 = residual_module(visible, 64)\r\n",
    "        layer2 = residual_module(layer1, 64)\r\n",
    "        layer3 = residual_module(layer2, 64)\r\n",
    "        p = Dense(4096,activation='softmax')(layer3)\r\n",
    "        v = Dense(1,activation = 'sigmoid')(layer3)\r\n",
    "        return Model(inputs=visible, outputs=[p,v])\r\n",
    "    \r\n",
    "    def predict(self,env):\r\n",
    "        input_values = generate_input(env.position_memory)\r\n",
    "        state_tensor = tf.convert_to_tensor(input_values)\r\n",
    "        p,v = self.model(state_tensor, training=False)\r\n",
    "        return p,v\r\n",
    "    \r\n",
    "    def explore(self,env):\r\n",
    "        action_space = np.random.randn(4096)\r\n",
    "        action_space = filter_legal_moves(env.board,action_space)\r\n",
    "        action = np.argmax(action_space, axis=None)\r\n",
    "        move= num2move[action]\r\n",
    "        return move,action\r\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "5d591f94785818b435df4881258bbd57da528693019fb2c63deaaf29b9986dd3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}